## 概述

在人工智能领域，神经网络宛如一颗不曾黯淡的明星，熠熠生辉。过去的十年，我们见证了业界的惊人进展。从为深度学习潜力背书的卷积神经网络，到战胜人类围棋高手的AlphaGo，再到备受瞩目的ChatGPT，神经网络不断为世界奉献着惊喜之作。然而，在令人欢欣鼓舞之余，它也带给我们更多困惑、不安与敬畏。神经网络的构思根源可追溯至仿生学，也就是借助计算机和数学模型来模拟人类神经系统。但就模型本身而言，我们对其了解仍相对有限，模型的运行原理似乎仍笼罩在一层迷雾之中。我们不仅对模型的运作机制知之甚少，甚至对其潜在极限的探知也颇为有限。

在当前的学术界和业界，关于神经网络的前景存在着明显的分歧。有一派阵营认为，当前的人工智能热潮可能只是一场泡沫，整个领域尚未取得实质性的突破。杰出学者Michael I. Jordan教授坚守此观点，他认为人工智能距离达到人类水平还存在相当大的差距。尽管神经网络在某些领域能够“模拟”智能，但从严谨的角度看，这并不能等同于真正的智能。另一阵营则坚信人工智能正站在突围的前夜，将为人类带来巨大便利。企业家（如扎克伯格和马化腾等人）持有这种观点。他们对人工智能的前景充满信心，认为其将促成一场新的工业革命，类似于电力一样，改变产业格局和人类生活。

当然，也有不少人担忧人工智能可能带来巨大的风险，因为我们正在创造一种在某种程度上类似永生的、全新类型的智能体，可以称之为**硅基生命**。业界的伊隆·马斯克（Elon Musk）和学术界的杰弗里·辛顿（Geoffrey Hinton）持有这种观点。尽管当前的人工智能尚未直接显现出威胁，但考虑到其迅猛的发展速度，未来（约5年或10年内）我们可能会面临人工智能带来的潜在风险。这种风险可能并不会如许多科幻电影所描绘的那样——人工智能对人类发动最终的审判之战并毁灭人类。然而，它确实可能引发大规模的失业问题，因为许多工作完全可以由人工智能来完成，导致许多人失去工作机会。

无论持有哪种观点，未来都已然降临。在面对人工智能时，你或许可以欣赏、引述、反驳、质疑、歌颂，抑或批评，却无法忽略其存在。理解并掌握神经网络的相关知识，已经成为新一代数据科学家必不可少的技能之一。在经过前几章的铺垫后，从本章起，我们将深入探讨神经网络模型：从最基础的**多层感知器模型**（Multilayer Perceptron，MLP）开始，详细剖析并证明深度学习潜能的[卷积神经网络（CNN）模型](../ch09_cnn)，接着介绍处理时序数据的[循环神经网络（RNN）](../ch10_rnn)，最终深入探讨如何训练和构建目前最先进的对话式人工智能模型（[大语言模型](../ch11_llm)），如ChatGPT。 


## 代码说明

|代码|说明|
|---|---|
|[utils.py](utils.py)| 定义多层感知器的模型组件，比如线性模型，Sigmoid函数等 |
|[perceptron.ipynb](perceptron.ipynb)| 展示感知器模型对应的计算图 |
|[logit_regression.ipynb](logit_regression.ipynb)| 按照神经网络的方式重新搭建逻辑回归模型，并训练模型 |
|[mlp.ipynb](mlp.ipynb)| 搭建多层感知器模型，并展示该模型的通用性 |
|[saturated\_activation_function.ipynb](saturated_activation_function.ipynb)| 通过计算图，展示坏死的神经细胞 |
|[activation_monitoring.ipynb](activation_monitoring.ipynb)| 监控模型的训练情况 |
|[activation_functions.ipynb](activation_functions.ipynb)| 常用的激活函数 |
|[initialization.ipynb](initialization.ipynb)| 参数初始化的优化方案 |
|[normalization.ipynb](normalization.ipynb)| 归一化层 |